{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solução Exercicio 1 - Trilha Dados\n",
    "\n",
    "<ol>\n",
    "    <li>Baixar 5 bases de dados</li>\n",
    "    <li>Organizar as bases de dados em uma pasta chamada datasets</li>\n",
    "    <li>Carregar as bases de dados</li>\n",
    "    <ol type=\"a\">\n",
    "        <li>Converter o nome das colunas para o formato \"nome_da_coluna\", ou seja, letras minúsculas e nome composto separado por   \"_\"\n",
    "        </li>\n",
    "        <li>converter os tipos de dados dos campos</li>\n",
    "        <li>tratar dados nulos</li>\n",
    "    </ol>\n",
    "    <li>Salvar as bases de dados processados em um arquivo novo arquivo .pkl</li>\n",
    "</od><br>\n",
    "\n",
    "Extra. Refatorar o código e separar o processamento dos dados em uma função que:<br>\n",
    "1. Dado o nome de um arquivo sem a extensão (ex.: movies.csv -> \"movies\")\n",
    "- Verificar se existe um arquivo .pkl com os dados processados,\n",
    "- se sim, abre este arquivo;\n",
    "- senão abre o arquivo cru, efetua o processamento, salva um arquivo .pkl\n",
    "- retorna os dados processados em um pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converter nome das colunas do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    if (df.iloc[::, 0].values == np.arange(df.shape[0])).all:\n",
    "        df.drop(columns=[df.columns[0]], inplace=True)\n",
    "\n",
    "    new_columns_names = df.columns.to_list()\n",
    "\n",
    "    new_columns_names = [column.replace(\"\\n\", \"_\") for column in new_columns_names]\n",
    "    new_columns_names = [column.replace(\",\", \"_or_\") for column in new_columns_names]\n",
    "    new_columns_names = [column.replace(\" \", \"_\") for column in new_columns_names]\n",
    "    new_columns_names = [column.replace(\"/\", \"_per_\") for column in new_columns_names]\n",
    "    new_columns_names = [column.replace(\"__\", \"_\") for column in new_columns_names]\n",
    "\n",
    "    for i_column, column in enumerate(new_columns_names):\n",
    "        temp = None\n",
    "        for i_letter in range(1, len(column)):\n",
    "            if column[i_letter].isupper():\n",
    "                temp = column[:i_letter:] + \"_\" + column[i_letter::] \n",
    "                temp = temp.replace(\"__\", \"_\")\n",
    "        \n",
    "        if temp:\n",
    "            new_columns_names[i_column]\n",
    "        \n",
    "    df.columns = list(map(str.lower, new_columns_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converter tipos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcasting_types(df):\n",
    "    for column in df.columns.tolist():\n",
    "        if df[column].dtype == \"object\":\n",
    "            try:  \n",
    "                df[column] = df[column].str.replace(\",\", \"\").astype(\"float64\")\n",
    "            except ValueError:\n",
    "                if len(df[column].unique()) <= 50:\n",
    "                    df[column] = df[column].astype(\"category\")\n",
    "                else:\n",
    "                    df[column] = df[column].astype(\"string\")\n",
    "                \n",
    "        if df[column].dtype == \"int64\":\n",
    "            if df[column].min() > -256 and df[column].max() < 256:\n",
    "                df[column] = df[column].astype(\"int8\")\n",
    "            if df[column].min() > -32768 and df[column].max() < 32768:\n",
    "                df[column] = df[column].astype(\"int16\")\n",
    "            elif df[column].min() > -2147483648 and df[column].max() < 2147483648:\n",
    "                df[column] = df[column].astype(\"int32\")\n",
    "                    \n",
    "        elif df[column].dtype == \"float64\":\n",
    "            if df[column].min() > -32768 and df[column].max() < 32768:\n",
    "                df[column] = df[column].astype(\"float16\")\n",
    "            elif df[column].min() > -2147483648 and df[column].max() < 2147483648:\n",
    "                df[column] = df[column].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nulls(df):\n",
    "    for column in df.columns.to_list():\n",
    "        null_count = df[column].isna().sum()\n",
    "        \n",
    "        if null_count > df.shape[0] * 0.35:\n",
    "            df.drop(column, inplace=True, axis=1)\n",
    "        elif null_count < df.shape[0] * 0.10:\n",
    "            if df[column].dtype in [\"category\", \"string\"]:\n",
    "                df[column].fillna(df[column].mode(), inplace=True)\n",
    "            else:\n",
    "                df[column].fillna(df[column].median(), inplace=True)\n",
    "            \n",
    "    df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar ou ler dados processados em arquivo .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_live\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230 entries, 0 to 229\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   country_or_other      230 non-null    string \n",
      " 1   total_cases           230 non-null    float32\n",
      " 2   total_deaths          230 non-null    float32\n",
      " 3   total_recovered       230 non-null    float32\n",
      " 4   active_cases          230 non-null    float32\n",
      " 5   tot_cases_per_1m_pop  230 non-null    float32\n",
      " 6   deaths_per_1m_pop     230 non-null    float16\n",
      " 7   total_tests           230 non-null    float32\n",
      " 8   tests_per_1m_pop      230 non-null    float32\n",
      " 9   population            230 non-null    float32\n",
      "dtypes: float16(1), float32(8), string(1)\n",
      "memory usage: 22.5 KB\n"
     ]
    }
   ],
   "source": [
    "names_dbs = ['covid_live', 'data_science_salaries', 'eplmatches', 'violence_against_women_girls_data', \n",
    "             'spotify_artist_data']\n",
    "\n",
    "def save_processed(names_dbs):\n",
    "    for name_db in names_dbs:\n",
    "        df = pd.read_csv(f\"databases/raw/{name_db}.csv\")\n",
    "    \n",
    "        rename_columns(df) \n",
    "        downcasting_types(df)\n",
    "        process_nulls(df)\n",
    "        \n",
    "        df.to_pickle(f'databases/processed/{name_db}.pkl')\n",
    "    \n",
    "def load_processed(name_db):\n",
    "    print(name_db)\n",
    "    try:\n",
    "        df = pd.read_pickle(f\"databases/processed/{name_db}.pkl\")\n",
    "    except FileNotFoundError:\n",
    "        save_processed([name_db])\n",
    "        df = pd.read_pickle(f\"databases/processed/{name_db}.pkl\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "save_processed(names_dbs[:-1:])  \n",
    "df = load_processed(f\"{names_dbs[0]}\")\n",
    "df.info(show_counts=True, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230 entries, 0 to 229\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   country_or_other      230 non-null    object \n",
      " 1   total_cases           230 non-null    object \n",
      " 2   total_deaths          225 non-null    object \n",
      " 3   new_deaths            3 non-null      float64\n",
      " 4   total_recovered       214 non-null    object \n",
      " 5   active_cases          215 non-null    object \n",
      " 6   serious_or_critical   147 non-null    object \n",
      " 7   tot_cases_per_1m_pop  228 non-null    object \n",
      " 8   deaths_per_1m_pop     223 non-null    object \n",
      " 9   total_tests           214 non-null    object \n",
      " 10  tests_per_1m_pop      214 non-null    object \n",
      " 11  population            228 non-null    object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 153.4 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"../exercicio_1/databases/raw/{names_dbs[0]}.csv\")\n",
    "rename_columns(df)\n",
    "df.info(show_counts=True, memory_usage='deep')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d674aba619e9128d5d95f68874c090de0e48b8e67c1ba838c5d294b8a6cf0663"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
